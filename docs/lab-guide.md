# New Relic ProcessSample Optimization Lab Guide

This comprehensive guide provides detailed instructions for using the New Relic ProcessSample Optimization Lab to reduce data ingest costs while maintaining essential observability capabilities.

## Understanding the Cost Challenge

ProcessSample events are generated by the New Relic Infrastructure agent to monitor process-level metrics. While valuable, these events can contribute significantly to data ingest costs due to:

1. High frequency (default: every 20 seconds)
2. High cardinality (one event per process)
3. Large event size (includes detailed process information)

The lab demonstrates proven approaches to optimize these costs without sacrificing observability.

## Lab Components

The lab consists of three primary components running in Docker containers:

1. **New Relic Infrastructure Agent (infra)**
   - Collects and sends ProcessSample events to New Relic
   - Configured with optimized sampling rate and filters
   - Runs with seccomp profile for security

2. **OpenTelemetry Collector (otel)**
   - Provides alternative system-level metrics
   - Collects hostmetrics at a 10-second interval
   - Complements the reduced ProcessSample data

3. **Synthetic Load Generator (load)**
   - Creates predictable CPU and memory usage
   - Configurable via environment variables
   - Useful for testing and validation

## Repository Structure

```
.
├── .env.example                 # Template for environment variables
├── config/                      # Configuration files
│   ├── newrelic-infra.yml       # NR Infrastructure Agent config
│   └── otel-config.yaml         # OpenTelemetry Collector config
├── docker-compose.yml           # Main container orchestration
├── overrides/                   # Scenario-specific configurations
│   ├── min-mounts.yml           # Minimal filesystem mounts
│   └── seccomp-disabled.yml     # Disabled security profile
├── profiles/                    # Security profiles
│   └── seccomp-nr.json          # Seccomp profile for containers
├── load-image/                  # Synthetic load generator
│   ├── Dockerfile               # Container image definition
│   └── entrypoint.sh            # Container startup script
└── scripts/                     # Utility scripts
    ├── validate_ingest.sh       # Ingest volume estimation
    └── ci_smoke.sh              # CI validation
```

## Core Optimization Strategies

### 1. Throttled Sample Rate

**Implementation**: 
The Infrastructure Agent is configured to collect ProcessSample events every 60 seconds instead of the default 20 seconds:

```yaml
# config/newrelic-infra.yml
metrics_process_sample_rate: 60
```

**Impact**:
- Approximately 67% reduction in event volume
- Minimal observability impact for most use cases
- Process starts/stops still detected, just with lower temporal resolution

**When to adjust**:
- Decrease to 30s if you need more frequent process data
- Increase to 120s for further cost reduction if 60s is sufficient

### 2. Process Filtering

**Implementation**:
The Infrastructure Agent is configured to exclude specific processes or patterns:

```yaml
# config/newrelic-infra.yml
exclude_matching_metrics:
  - process.*.*
```

**Customization options**:
You can modify the filters to target specific processes, for example:

```yaml
exclude_matching_metrics:
  - process.systemd.*
  - process.sshd.*
  - process.daemon.*
```

**Impact**:
- Further reduces data volume beyond sample rate changes
- Focuses monitoring on critical processes
- Reduces "noise" from system processes

### 3. OpenTelemetry Hostmetrics

**Implementation**:
The OpenTelemetry Collector is configured to collect system-level metrics:

```yaml
# config/otel-config.yaml
receivers:
  hostmetrics:
    collection_interval: 10s
```

**Impact**:
- Provides high-frequency visibility into system resources
- Enables effective dashboarding and alerting
- Complements the reduced ProcessSample data

## Lab Scenarios in Detail

### 1. Standard Lab (Default)

**Use case**: General cost optimization with balanced security

**Configuration**: Default setup with 60s sample rate, filtering, and seccomp

**Expected outcomes**:
- ~70% reduction in ProcessSample ingest
- Full visibility into host metrics
- Strong security posture

**Verification**:
Run `make validate` after at least 5 minutes to see the GB of ProcessSample data ingested.

### 2. Minimal-Mounts Mode

**Use case**: High-security environments with limited filesystem access requirements

**Configuration**: 
Uses `min-mounts.yml` override to limit filesystem access to only `/proc` and `/sys`

**Command**:
```bash
COMPOSE_FILE=docker-compose.yml:overrides/min-mounts.yml make up
```

**Key differences**:
- No filesystem/disk metrics available
- Significantly reduced attack surface
- Same cost savings as Standard Lab

**Ideal for**:
- Production environments with strict security requirements
- When disk/filesystem metrics aren't critical

### 3. Seccomp-Off Troubleshooting

**Use case**: Debugging seccomp-related issues or testing new agent features

**Configuration**:
Disables seccomp profile restrictions, allowing all syscalls

**Command**:
```bash
COMPOSE_FILE=docker-compose.yml:overrides/seccomp-disabled.yml make up
```

**When to use**:
- If you encounter "seccomp blocked syscall" errors
- When testing new Infrastructure Agent features
- For identifying syscalls needed for new functionality

**Security note**:
Only use temporarily for debugging, then return to a secured configuration.

### 4. Container Metrics (docker_stats)

**Use case**: When detailed container-level metrics are required

**Configuration changes**:

1. Add docker_stats receiver to `config/otel-config.yaml`:
   ```yaml
   receivers:
     docker_stats:
       endpoint: "unix:///var/run/docker.sock"
   ```

2. Add Docker socket volume to the OTel service in `docker-compose.yml`:
   ```yaml
   volumes:
     - /var/run/docker.sock:/var/run/docker.sock:ro
   ```

3. Update the service pipeline:
   ```yaml
   service:
     pipelines:
       metrics:
         receivers: [hostmetrics, docker_stats]
   ```

**Security implications**:
- Exposes Docker socket to the container
- Significantly increases the attack surface
- Use only when container metrics are essential

### 5. Baseline Measurement

**Use case**: Establishing a baseline for comparison or cost justification

**Configuration changes**:
1. Edit `config/newrelic-infra.yml`:
   ```yaml
   metrics_process_sample_rate: 20  # Change from 60 to 20
   # Comment out the exclude_matching_metrics section
   ```

2. Run `make up` followed by `make validate` after a few minutes

**Purpose**:
- Demonstrates unoptimized ingest volume
- Provides comparison for ROI calculations
- Helps justify the optimization effort

## Key Configuration Files

### 1. New Relic Infrastructure Configuration

The `config/newrelic-infra.yml` file controls the ProcessSample collection behavior:

```yaml
enable_process_metrics: true
metrics_process_sample_rate: 60
collect_process_commandline: false
exclude_matching_metrics:
  - process.*.*
```

### 2. OpenTelemetry Configuration

The `config/otel-config.yaml` file configures the OpenTelemetry Collector:

```yaml
extensions:
  health_check: {}
receivers:
  hostmetrics:
    collection_interval: 10s
processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 400
  filter/core-metrics:
    metrics:
      exclude:
        match_type: regexp
        metric_names: ["process.*"]
  batch: {}
exporters:
  otlp:
    endpoint: "otlp.nr-data.net:4317"
    headers:
      api-key: "${NEW_RELIC_LICENSE_KEY}"
service:
  extensions: [health_check]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: [memory_limiter, filter/core-metrics, batch]
      exporters: [otlp]
```

### 3. Security Profile

The `profiles/seccomp-nr.json` file defines the allowed syscalls for the containers:

```json
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "syscalls": [
    {
      "names": [
        "read", "write", "exit", "sigreturn", "futex", "clock_gettime",
        "openat", "close", "newfstatat", "lseek", "mmap", "munmap",
        "rt_sigaction", "rt_sigprocmask", "getpid", "getppid", "getuid",
        "getgid", "geteuid", "getegid", "clone", "wait4", "prctl",
        "arch_prctl", "socket", "connect", "recvfrom", "sendto",
        "utimensat", "statfs", "uname", "ioctl"
      ],
      "action": "SCMP_ACT_ALLOW"
    }
  ]
}
```

## Security Considerations

### Full-Host Mount Considerations

The default configuration mounts the entire host filesystem (`/:/host:ro`) to provide complete metrics. This has security implications:

**Risks**:
- Increased attack surface
- Potential access to sensitive files if container is compromised
- May violate security policies in some organizations

**Mitigation options**:
1. Use Minimal-Mounts mode for production
2. Create custom mounts for specific directories needed
3. Implement additional container security controls

### Seccomp Profile Details

The seccomp profile restricts container syscalls to a minimal allowed set. This significantly reduces the attack surface by limiting which system calls containers can make.

**Note**: If you encounter syscall blocking, use Seccomp-Off mode to identify required syscalls, then add them to the profile.

## Troubleshooting

### "seccomp blocked syscall" Errors

**Symptoms**:
- Container exits unexpectedly
- Logs show "seccomp blocked syscall" errors

**Solutions**:
1. Temporarily disable seccomp:
   ```bash
   COMPOSE_FILE=docker-compose.yml:overrides/seccomp-disabled.yml make up
   ```

2. Identify the blocked syscalls from the logs:
   ```bash
   make logs
   ```

3. Add the required syscalls to `profiles/seccomp-nr.json`

### Missing Process Metrics

**Symptoms**:
- No ProcessSample events in New Relic
- No reduction shown in `make validate`

**Solutions**:
1. Verify license key in `.env`
2. Check for errors in Infrastructure Agent logs:
   ```bash
   make logs
   ```
3. Ensure `enable_process_metrics: true` in `config/newrelic-infra.yml`

### Validation Script Errors

**Symptoms**:
- `make validate` fails with API errors

**Solutions**:
1. Verify `NEW_RELIC_API_KEY` and `NR_ACCOUNT_ID` in `.env`
2. Ensure `jq` is installed
3. Check network connectivity to New Relic API

## NRQL Queries for Analysis

Once data is flowing to New Relic, use these NRQL queries to analyze your ProcessSample data:

1. **Volume by process name**:
   ```sql
   SELECT bytecountestimate()/1e9 as 'GB' FROM ProcessSample FACET processDisplayName LIMIT 10 SINCE 1 hour ago
   ```

2. **Process resource usage**:
   ```sql
   SELECT average(cpuPercent), average(memoryResidentSizeBytes)/1024/1024 as 'Memory (MB)' 
   FROM ProcessSample FACET processDisplayName LIMIT 10 SINCE 1 hour ago
   ```

3. **ProcessSample event rate**:
   ```sql
   SELECT count(*)/60 as 'Events per minute' FROM ProcessSample TIMESERIES SINCE 1 hour ago
   ```

## Best Practices for Implementation

1. **Start with the Standard Lab configuration**
   - Begin with 60s sampling and basic filtering
   - Measure impact with `make validate`

2. **Customize filtering for your environment**
   - Identify high-volume, low-value processes
   - Create specific exclusion patterns

3. **Balance frequency and observability**
   - Consider 30s sampling if 60s is too infrequent
   - Use OTel hostmetrics for high-frequency system data

4. **Secure appropriately for your environment**
   - Use minimal mounts in production
   - Keep seccomp enabled outside of debugging

5. **Validate and iterate**
   - Regularly measure ingest volume
   - Adjust configuration based on real data

## Expected Outcomes

When properly implemented, you can expect:

| Configuration | Sample Rate | Filtering | Expected Volume Reduction |
|---------------|-------------|-----------|---------------------------|
| Standard | 60s | Yes | ~70-75% |
| Minimal-Mounts | 60s | Yes | ~70-75% |
| With Container Metrics | 60s | Yes | ~65-70% |

## Automated Scenarios and Reporting

The lab includes scripts for running automated scenarios and generating detailed reports:

### Running Scenario Tests

You can run multiple scenarios automatically and compare their results using:

```bash
./scripts/run_scenarios.sh [duration_minutes]
```

This will:
1. Run each configured scenario for the specified duration (default: 30 minutes)
2. Collect ingest metrics for each scenario
3. Generate a summary report comparing the results

The scenarios include:
- **Standard** (60s sampling with filtering)
- **Minimal Mounts** (restricted filesystem access)
- **Baseline** (20s sampling for comparison)

### Generating NRDB Reports

For more detailed analysis, you can generate reports based on NRQL queries:

```bash
./scripts/generate_nrdb_report.sh
```

This script queries the New Relic database to create detailed reports on:
- ProcessSample volume over time
- Volume by host and process
- CPU and memory usage metrics
- Average event size

### Visualizing Results

To visualize the comparison between scenarios:

```bash
python scripts/generate_visualization.py
```

This generates charts comparing ingest volumes and creates a detailed Markdown report with analysis.

### GitHub Actions for Long-Running Experiments

The repository includes a GitHub Actions workflow for running long-duration experiments:

1. Go to the "Actions" tab in the repository
2. Select the "Data Experiment" workflow
3. Click "Run workflow"
4. Configure:
   - Duration in minutes for each scenario
   - Which scenarios to run
5. The results will be uploaded as artifacts when complete

This allows you to run experiments for hours to get statistically significant data without keeping your local machine running.

## Conclusion

The New Relic ProcessSample Optimization Lab provides a practical, hands-on approach to reducing data ingest costs without sacrificing essential observability. By implementing the strategies demonstrated in this lab and using the automated testing tools, organizations can achieve significant cost savings while maintaining the ability to effectively monitor and troubleshoot their infrastructure.
